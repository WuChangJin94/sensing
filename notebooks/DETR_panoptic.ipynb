{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzkJUMTxn8hB"
   },
   "source": [
    "# Panoptic segmentation using DETR\n",
    "\n",
    "In this notebook we demonstrate how to explore the panoptic segmentation capabilities of DETR. The prediction occurs in several steps:\n",
    "\n",
    "1.   The model predicts a box and a binary mask for each object queries\n",
    "2.   We filter the predictions for which the confidence is < 85%\n",
    "3.   Finally, the remaining masks are merged together using a pixel-wise argmax\n",
    "\n",
    "For simplicity, we rely on DETR's postprocessor to execute 2 and 3. We encourage to take a look at the corresponding code to get a better understanding of the process.\n",
    "\n",
    "Finally, we visualize the final prediction using Detectron2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D94dCpHipOx6"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wObDPOY2poRT"
   },
   "source": [
    "This section contains the necessary boiler-plate. Run it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WCXaQ4VaJXv0"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as T\n",
    "import numpy\n",
    "torch.set_grad_enabled(False);\n",
    "\n",
    "import os\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtMDds6mpwfn"
   },
   "source": [
    "The panoptic API is required for panoptic inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cocodataset/panopticapi.git\n",
      "  Cloning https://github.com/cocodataset/panopticapi.git to /tmp/pip-req-build-jo_1n5p1\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/panopticapi.git /tmp/pip-req-build-jo_1n5p1\n",
      "  Resolved https://github.com/cocodataset/panopticapi.git to commit 7bb4655548f98f3fedc07bf37e9040a992b054b0\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from panopticapi==0.1) (1.24.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from panopticapi==0.1) (10.3.0)\n",
      "Building wheels for collected packages: panopticapi\n",
      "  Building wheel for panopticapi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for panopticapi: filename=panopticapi-0.1-py3-none-any.whl size=8259 sha256=2d4aff403adf3f566179dc9089c6f75741a083d70fcde6af3d9a1d80c2a1db7a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0xmuu1rq/wheels/b3/fc/e3/2463e5db55087b06e9c3bb117af1a63a080d1ec4c33291cec9\n",
      "Successfully built panopticapi\n",
      "Installing collected packages: panopticapi\n",
      "Successfully installed panopticapi-0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/cocodataset/panopticapi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0Ys8lZhFCwXe"
   },
   "outputs": [],
   "source": [
    "import panopticapi\n",
    "from panopticapi.utils import id2rgb, rgb2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QD4mQxHIqGCr"
   },
   "outputs": [],
   "source": [
    "# These are the COCO classes\n",
    "CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "\n",
    "# Detectron2 uses a different numbering scheme, we build a conversion table\n",
    "coco2d2 = {}\n",
    "count = 0\n",
    "for i, c in enumerate(CLASSES):\n",
    "  if c != \"N/A\":\n",
    "    coco2d2[i] = count\n",
    "    count+=1\n",
    "\n",
    "# standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([\n",
    "    T.Resize(800),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMFPx33oqjl-"
   },
   "source": [
    "## Using a model from hub\n",
    "\n",
    "We load a pre-trained model directly from torch hub. Note that we also request the post-processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5uUW5iRnJhxM",
    "outputId": "f57bd101-f300-47da-e88d-803c372cb898"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/detr/zipball/main\" to /home/arg/.cache/torch/hub/main.zip\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /home/arg/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 171M/171M [00:02<00:00, 67.5MB/s]\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/detr/detr-r101-panoptic-40021d53.pth\" to /home/arg/.cache/torch/hub/checkpoints/detr-r101-panoptic-40021d53.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 237M/237M [00:07<00:00, 33.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "model, postprocessor = torch.hub.load('facebookresearch/detr', 'detr_resnet101_panoptic', pretrained=True, return_postprocessor=True, num_classes=250)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocODwfQCrdMJ"
   },
   "source": [
    "Next, we retrieve an image on which we wish to test the model. Here, we use an image from the validation set of COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from path\n",
    "path = 'image2.jpg'\n",
    "im = Image.open(path).convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-teJ9yAUryIG"
   },
   "source": [
    "Finally, we run the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3oUWwJCKIlD"
   },
   "outputs": [],
   "source": [
    "# mean-std normalize the input image (batch-size: 1)\n",
    "img = transform(im).unsqueeze(0)\n",
    "out = model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is76xRRYsC3y"
   },
   "source": [
    "This returns a mask for each query, let us visualize the high confidence ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-5ytUV_qsVhL",
    "outputId": "fde4abea-96c3-4c58-8c34-316222900c18"
   },
   "outputs": [],
   "source": [
    "# compute the scores, excluding the \"no-object\" class (the last one)\n",
    "scores = out[\"pred_logits\"].softmax(-1)[..., :-1].max(-1)[0]\n",
    "# threshold the confidence\n",
    "keep = scores > 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjDRLX3yDrlH"
   },
   "source": [
    "Now that we have the individual masks, we can merge the predictions into a unified panoptic segmentation. We use DETR's postprocessor for that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LurQI5Z-Ay1Z"
   },
   "outputs": [],
   "source": [
    "# the post-processor expects as input the target size of the predictions (which we set here to the image size)\n",
    "result = postprocessor(out, torch.as_tensor(img.shape[-2:]).unsqueeze(0))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSrX5h15EU-O"
   },
   "source": [
    "We can now do a simple visualization of the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKxteXUKvQZ-"
   },
   "source": [
    "## Panoptic visualization using Detectron2\n",
    "\n",
    "In this section we demonstrate how to obtain a better looking visualization by leveraging Detectron2's plotting utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clR1302-IV7x",
    "outputId": "0a698dde-e52e-4dbf-9e75-509a5256ade9"
   },
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRG38DsytU7G"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEZkdoc-wC7m"
   },
   "source": [
    "Finally, we visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "rYoKWqFyBWE9",
    "outputId": "7f0c2498-1349-44e6-b21e-263977751e36"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "# We extract the segments info and the panoptic result from DETR's prediction\n",
    "segments_info = deepcopy(result[\"segments_info\"])\n",
    "# Panoptic predictions are stored in a special format png\n",
    "panoptic_seg = Image.open(io.BytesIO(result['png_string']))\n",
    "final_w, final_h = panoptic_seg.size\n",
    "# We convert the png into an segment id map\n",
    "panoptic_seg = numpy.array(panoptic_seg, dtype=numpy.uint8)\n",
    "panoptic_seg = torch.from_numpy(rgb2id(panoptic_seg))\n",
    "\n",
    "# Detectron2 uses a different numbering of coco classes, here we convert the class ids accordingly\n",
    "meta = MetadataCatalog.get(\"coco_2017_val_panoptic_separated\")\n",
    "for i in range(len(segments_info)):\n",
    "    c = segments_info[i][\"category_id\"]\n",
    "    segments_info[i][\"category_id\"] = meta.thing_dataset_id_to_contiguous_id[c] if segments_info[i][\"isthing\"] else meta.stuff_dataset_id_to_contiguous_id[c]\n",
    "\n",
    "\n",
    "# Finally we visualize the prediction\n",
    "v = Visualizer(numpy.array(im.copy().resize((final_w, final_h)))[:, :, ::-1], meta, scale=1.0)\n",
    "v._default_font_size = 20\n",
    "v = v.draw_panoptic_seg_predictions(panoptic_seg, segments_info, area_threshold=0)\n",
    "plt.imshow(v.get_image())\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定保存路径\n",
    "save_dir = './DETR_result/image2/'\n",
    "# 如果目录不存在，则创建\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 初始化字典来存储每个类别的掩码\n",
    "masks_dict = {}\n",
    "category_names = {}\n",
    "\n",
    "# 合并相同标签的掩码\n",
    "for i, mask in enumerate(out[\"pred_masks\"][keep]):\n",
    "    if i >= len(segments_info):\n",
    "        print(f\"Warning: Skipping index {i} as it exceeds the length of segments_info\")\n",
    "        continue\n",
    "    \n",
    "    # 转换为二进制形式\n",
    "    mask = (mask > 0.5).cpu().numpy().astype(np.uint8) * 255\n",
    "    category_id = segments_info[i]['category_id']\n",
    "    isthing = segments_info[i]['isthing']\n",
    "    category_name = meta.thing_classes[category_id] if isthing else meta.stuff_classes[category_id]\n",
    "    \n",
    "    if category_id not in masks_dict:\n",
    "        masks_dict[category_id] = mask\n",
    "    else:\n",
    "        masks_dict[category_id] = np.maximum(masks_dict[category_id], mask)\n",
    "    \n",
    "    category_names[category_id] = category_name\n",
    "\n",
    "# 获取排序后的类别标签\n",
    "sorted_category_ids = sorted(masks_dict.keys())\n",
    "\n",
    "# 保存合并后的掩码并输出图片类别文件\n",
    "image_categories_file = os.path.join(save_dir, 'image_categories.txt')\n",
    "with open(image_categories_file, 'w') as f:\n",
    "    for category_id in sorted_category_ids:\n",
    "        merged_mask = masks_dict[category_id]\n",
    "        mask_img = Image.fromarray(merged_mask)\n",
    "        mask_img.save(os.path.join(save_dir, f'mask_class_{category_id}.png'))\n",
    "        category_name = category_names[category_id]\n",
    "        f.write(f'Label ID: {category_id}, Category: {category_name}\\n')\n",
    "\n",
    "print(f\"Files saved to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear folder\n",
    "import shutil\n",
    "# Define the folder path you want to delete\n",
    "folder_to_delete = './DETR_result/image2/'\n",
    "\n",
    "# Check if the folder exists and delete it\n",
    "if os.path.exists(folder_to_delete):\n",
    "    shutil.rmtree(folder_to_delete)\n",
    "    print(f\"Folder '{folder_to_delete}' has been deleted.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_to_delete}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DETR_panoptic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
